{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of raw FASTQ files\n",
    "This notebook is for quality trimming of raw fastq files. The raw files are expected to be already uploaded in the Hopsworks HDFS. It applies `trimmomatic` and `cutadapt` tools. For trimmomatic, paired end mode is used and both paired and unpaired output files are preserved. For cutadapt processing only **paired R2** files are used as input. Different arguments can be set in `settings.yml` file.\n",
    "\n",
    "Note: Currently only RNA sequence processing is supported via  value of flag `IS_RNA` set to `True`. DNA sequencing is not yet supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WIP notes\n",
    "\n",
    "* trimmomatic jar hopy to local throws error\n",
    "* subprocess throws error in invalid adapters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from hops import hdfs\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=utils.load_arguments(sys.argv)\n",
    "\n",
    "if args is not None:\n",
    "    args=args['Trimmomatic']\n",
    "else :\n",
    "    sys.exit(utils.NO_CONFIG_ERR)\n",
    "    \n",
    "sc = SparkContext.getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_ROOT=args['OUTPUT_ROOT']\n",
    "OUTPUT_PAIRED=args['OUTPUT_PAIRED']\n",
    "OUTPUT_UNPAIRED=args['OUTPUT_UNPAIRED']\n",
    "INPUT_ROOT=args['INPUT_ROOT']\n",
    "USE_CUTADAPT = args['USE_CUTADAPT']\n",
    "IS_RNA = args['IS_RNA']\n",
    "\n",
    "PHRED = args['PHRED']\n",
    "LEADING = str(args['LEADING'])\n",
    "TRAILING = str(args['TRAILING'])\n",
    "SLIDING_WINDOW = str(args['SLIDINGWINDOW'])\n",
    "MIN_LEN = str(args['MINLEN'])\n",
    "THREADS = args['THREADS']\n",
    "JAVA = \"java -jar\"\n",
    "CUTADPAT_ARGS='cutadapt -j 0 -u 3 -o'\n",
    "SPACE=utils.SPACE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimmomatic jar version and adpaters\n",
    "tool=utils.find_file_like('trimmomatic')\n",
    "if tool is None:\n",
    "    sys.exit(utils.TRIMMOMATIC_NOT_FOUND)\n",
    "    \n",
    "ADAPTER=utils.find_file_like('TruSeq')\n",
    "if tool is None:\n",
    "    sys.exit(utils.TRIMMOMATIC_ADAPTER_NOT_FOUND)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files=hdfs.ls(INPUT_ROOT)\n",
    "\n",
    "### pair R1 and R2 for paired processing by trimmomatic\n",
    "pairedList =  utils.group_R1R2(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### TODO \n",
    "# flag for RNA /DN change adapters\n",
    "# single ended\n",
    "\n",
    "\n",
    "### paired end attributes\n",
    "\n",
    "illuminaclip_adapters = \"ILLUMINACLIP:\"+ADAPTER+\":2:30:10:2:keepBothReads\"\n",
    "illuminaclip_Attribute = \"LEADING:\"+LEADING+SPACE+\"TRAILING:\"+TRAILING+SPACE+\"SLIDINGWINDOW:\"+SLIDING_WINDOW+SPACE+\"MINLEN:\"+MIN_LEN\n",
    "\n",
    "# cutadpat\n",
    "def cut(input_file):\n",
    "    \n",
    "    out_trim='cut_'+input_file\n",
    "    params={out_trim : input_file}\n",
    "    cmd_cut=utils.build_command(CUTADPAT_ARGS, params)\n",
    "  \n",
    "    subprocess.run(cmd_cut.split(' '),check=True).returncode\n",
    "    if out_trim:\n",
    "        os.remove(input_file)\n",
    "        os.rename(out_trim,input_file)\n",
    "        \n",
    "    params.clear()\n",
    "\n",
    "\n",
    "\n",
    "### trimmomatic on paired files\n",
    "def apply_trim_paired(x):\n",
    "    \n",
    "    filename_forward=x[0] # R1\n",
    "    filename_reverse=x[1] # R2\n",
    "\n",
    "    hdfs.copy_to_local(os.path.join(INPUT_ROOT,filename_forward), overwrite=True)\n",
    "    hdfs.copy_to_local(os.path.join(INPUT_ROOT,filename_reverse), overwrite=True)\n",
    "    \n",
    "    output_forward_paired ='trim_paired_'+filename_forward\n",
    "    output_forward_unpaired='trim_unpaired_'+filename_forward\n",
    "    output_reverse_paired ='trim_paired_'+filename_reverse\n",
    "    output_reverse_unpaired='trim_unpaired_'+filename_reverse\n",
    "    \n",
    "    parameters = { 'PE ':'-'+PHRED, '-threads': THREADS, filename_forward: utils.EMPTY, filename_reverse: utils.EMPTY,\n",
    "                  output_forward_paired: utils.EMPTY, output_forward_unpaired: utils.EMPTY,\n",
    "                  output_reverse_paired: utils.EMPTY, output_reverse_unpaired:utils.EMPTY,\n",
    "                  illuminaclip_adapters: utils.EMPTY, illuminaclip_Attribute: utils.EMPTY                 \n",
    "                 }\n",
    "    \n",
    "    \n",
    "    cmd_paired=utils.build_command(JAVA+SPACE+tool, parameters)\n",
    "    \n",
    "    os.system(cmd_paired) # run\n",
    "  \n",
    "    status=False\n",
    "    if os.path.exists(output_forward_paired):\n",
    "        if USE_CUTADAPT:\n",
    "            cut(output_reverse_paired)        \n",
    "            \n",
    "        hdfs.copy_to_hdfs(output_forward_paired, OUTPUT_PAIRED, overwrite=True)\n",
    "        hdfs.copy_to_hdfs(output_forward_unpaired, OUTPUT_UNPAIRED, overwrite=True)\n",
    "        hdfs.copy_to_hdfs(output_reverse_paired, OUTPUT_PAIRED, overwrite=True)\n",
    "        hdfs.copy_to_hdfs(output_reverse_unpaired, OUTPUT_UNPAIRED, overwrite=True)\n",
    "        \n",
    "        os.remove(output_reverse_paired) \n",
    "        os.remove(output_forward_unpaired)\n",
    "        os.remove(output_forward_paired) \n",
    "        os.remove(output_reverse_unpaired) \n",
    "        os.remove(filename_forward)\n",
    "        os.remove(filename_reverse)\n",
    "        status=True\n",
    "        \n",
    "    parameters.clear()\n",
    "    return [status,output_forward_paired,output_forward_unpaired,output_reverse_paired,output_reverse_unpaired]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPairedRdd=sc.parallelize(pairedList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run \n",
    "trimmedFiles=dataPairedRdd.map(apply_trim_paired).collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}