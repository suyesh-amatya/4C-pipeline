{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nextgenmap\n",
    "Runs `nextgenmap` in paired and single end setting. Samples are grouped by `R1` and `R2` in file names.\n",
    "If the keyword `R` is not found its treated as a single ended file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import traceback\n",
    "import stat\n",
    "\n",
    "from hops import hdfs\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args=utils.load_arguments(sys.argv)\n",
    "#args=utils.load_arguments([0,'hdfs:///Projects/TCGA_viruses/Jupyter/pipeline/settings_DJ.yml'])\n",
    "\n",
    "if args is not None:\n",
    "    args=args[utils.KEY_NGM]\n",
    "else :\n",
    "    sys.exit(utils.NO_CONFIG_ERR)\n",
    "    \n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "VERY_FAST='--very-fast'\n",
    "INPUT_ROOT=args['INPUT_ROOT']\n",
    "OUTPUT_ROOT=args['OUTPUT_ROOT']\n",
    "REFERENCE_PATH=args['REFERENCE_FILE']\n",
    "MIN_I=str(args['MIN-IDENTITY'])\n",
    "MIN_R=str(args['MIN-RESIDUES'])\n",
    "THREADS=args['THREADS']\n",
    "LOG_DIR=args['LOGS_ROOT']\n",
    "is_very_fast=args['VERY_FAST']\n",
    "SPACE=utils.SPACE\n",
    "TOOL_PATH='hdfs:///Projects/4C/Tools/ngm_built/NGM'\n",
    "TOOL='./NGM/bin/ngm-0.5.5/ngm'\n",
    "\n",
    "\n",
    "\n",
    "def chmod_exec(tool):\n",
    "    st = os.stat(tool)\n",
    "    os.chmod(tool, st.st_mode | stat.S_IEXEC)\n",
    "\n",
    "def install_ngm(tool_path):\n",
    "    hdfs.copy_to_local(tool_path)\n",
    "    lib1='./NGM/bin/ngm-0.5.5/ngm-core'\n",
    "    lib2='./NGM/bin/ngm-0.5.5/ngm'\n",
    "    chmod_exec(lib1)\n",
    "    chmod_exec(lib2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Runs NGM in paired mode via subprocess for single R1 R2 pair.\n",
    "Output is saved in SAM format and copied back to hdfs.\n",
    "\"\"\"\n",
    "def apply_ngm_paired(x,REFERENCE_PATH): ### paired files\n",
    "\n",
    "    filename_forward_path=x[0] #r1\n",
    "    filename_reverse_path=x[1] #r2\n",
    "    # split path to get file names\n",
    "    filename_forward=os.path.basename(filename_forward_path)\n",
    "    filename_reverse=os.path.basename(filename_reverse_path)\n",
    "\n",
    "    output_file=filename_forward.split('.')[0].replace(utils.R1,'')\n",
    "    if  utils.skip_file(filename_forward,output_file,OUTPUT_ROOT):\n",
    "        return [-1]\n",
    "\n",
    "    if not os.path.exists(os.path.basename(TOOL_PATH)):\n",
    "        install_ngm(TOOL_PATH)\n",
    "\n",
    "    # get file name and copy to local\n",
    "    ref=os.path.split(REFERENCE_PATH)[1]\n",
    "    if not os.path.exists(ref):        \n",
    "        hdfs.copy_to_local(REFERENCE_PATH)\n",
    "    hdfs.copy_to_local(filename_forward_path, overwrite=True)\n",
    "    hdfs.copy_to_local(filename_reverse_path, overwrite=True)\n",
    "    \n",
    "\n",
    "    parameters = { '-i':MIN_I, '-R': MIN_R, '-p': utils.EMPTY, '-r': ref, '-1': filename_forward, '-2': filename_reverse,\n",
    "                  '--silent-clip': utils.EMPTY, '-o': output_file, '-t': THREADS, '--no-progress': utils.EMPTY }\n",
    "    \n",
    "    cmd = utils.build_command(TOOL,parameters)\n",
    "    if is_very_fast :\n",
    "        cmd=cmd+SPACE+VERY_FAST # final command to run\n",
    "    \n",
    "    logging.info('Running nextgenmap with command:', cmd)\n",
    "    log_file=os.path.splitext(output_file) [0]+'.txt'\n",
    "    f=open(log_file, \"w\")\n",
    "    # run\n",
    "    try:\n",
    "        execStatus=subprocess.run(cmd.split(),stdout=f,stderr=f)\n",
    "        hdfs.copy_to_hdfs(log_file, LOG_DIR, overwrite=True)\n",
    "        f.close()\n",
    "        status=False\n",
    "        if execStatus.returncode==0 and os.path.exists(output_file):\n",
    "             # copy output to hdfs\n",
    "            hdfs.copy_to_hdfs(output_file, OUTPUT_ROOT, overwrite=True)\n",
    "            status=True\n",
    "            # remove from local\n",
    "            os.remove(output_file)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        raise RuntimeError('Failed execution for input ', x )\n",
    "    finally:\n",
    "        os.remove(filename_forward)\n",
    "        os.remove(filename_reverse)\n",
    "        os.remove(log_file)\n",
    "\n",
    "        parameters.clear()\n",
    "    \n",
    "    return [status,output_file]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Runs NGM in single mode for single file.\n",
    "Output is in SAM format and copied back to hdfs.\n",
    "\"\"\"\n",
    "def apply_ngm_single(x,REFERENCE_PATH): ### paired files\n",
    "    \n",
    "    \n",
    "    filename_forward_path=x\n",
    "    # split path to get file names\n",
    "    filename_forward=os.path.basename(filename_forward_path)\n",
    "    output_file=filename_forward.split('.')[0].replace(utils.R1,'')+'.sam'\n",
    "    # skip if output exists\n",
    "    if  utils.skip_file(filename_forward,output_file,OUTPUT_ROOT):\n",
    "         return [-1]\n",
    "    # get file name\n",
    "    ref=os.path.split(REFERENCE_PATH)[1]\n",
    "    if not os.path.exists(ref):\n",
    "        hdfs.copy_to_local(REFERENCE_PATH,overwrite=False)\n",
    "\n",
    "    hdfs.copy_to_local(filename_forward_path, overwrite=True)\n",
    "\n",
    "    parameters = { '-i':MIN_I, '-R': MIN_R, '-q': filename_forward, '-r': ref, \n",
    "                  '--silent-clip': utils.EMPTY, '-o': output_file, '-t': THREADS, '--no-progress': utils.EMPTY }\n",
    "    \n",
    "    cmd = utils.build_command(TOOL,parameters)\n",
    "    \n",
    "    if is_very_fast :\n",
    "        cmd=cmd+SPACE+VERY_FAST # final command to run\n",
    "    \n",
    "    logging.info('Running nextgenmap with command:', cmd)\n",
    "    log_file=os.path.splitext(output_file) [0]+'.txt'\n",
    "    f=open(log_file, \"w\")\n",
    "    # run command    \n",
    "    subprocess.run(cmd.split(),stdout=f,stderr=f)\n",
    "    \n",
    "    hdfs.copy_to_hdfs(log_file, LOG_DIR, overwrite=True)\n",
    "    f.close()\n",
    "    status=False\n",
    "    if os.path.exists(output_file):    \n",
    "        # copy to hdfs\n",
    "        hdfs.copy_to_hdfs(output_file, OUTPUT_ROOT, overwrite=True)\n",
    "        status=True\n",
    "        # remove from local \n",
    "        os.remove(filename_forward)    \n",
    "        os.remove(output_file)\n",
    "        os.remove(log_file)\n",
    "        \n",
    "    parameters.clear()          \n",
    "    \n",
    "    return [status,output_file]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all input files hdfs path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_files=utils.load_file_names(INPUT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get list of all single end files and run NGM in single mode in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### single\n",
    "single_files=[f for f in all_files if utils.R_IDENTIFIER not in f]\n",
    "\n",
    "\n",
    "print('number of single input  files processing ', len(single_files))\n",
    "dataRdd=sc.parallelize(single_files)\n",
    "\n",
    "# run\n",
    "ngmSingleFiles=dataRdd.map(lambda x: apply_ngm_single(x,REFERENCE_PATH)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair R1 and R2 as a tuple in a list and run NGM in paired end in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group r1 and r2\n",
    "pairedList = utils.group_R1R2(all_files)\n",
    "dataPairedRdd=sc.parallelize(pairedList,sc.getConf().get(\"spark.executor.instances\"))\n",
    "\n",
    "# run\n",
    "try:\n",
    "    ngmFiles=dataPairedRdd.map(lambda x: apply_ngm_paired(x,REFERENCE_PATH) ).collect()\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    raise SystemError('Failed job execution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fd840124",
   "language": "python",
   "display_name": "PyCharm (ki-pipeline)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}